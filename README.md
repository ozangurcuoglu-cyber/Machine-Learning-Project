# Machine Learning Homeworks

This repository contains my university machine learning assignments.

## Contents
- **PNN Models Assignment** â€” Implementation and comparison of Probabilistic Neural Network architectures.
- **Predicting Road Accidents (Kaggle Competition)** â€” End-to-end data pipeline, feature engineering, and model training for road accident prediction.

---

**Author:** Ozan GÃ¼rcÃ¼oÄŸlu  
**Environment:** Python, Jupyter Notebook, scikit-learn, NumPy, pandas







# Predicting Road Accidents (Kaggle Competition) --> **ML_HW_3.ipynb**

A Kaggle competition project focused on predicting the likelihood of road accidents based on environmental and traffic-related data.

## Key Steps
- Data cleaning and feature engineering
- Model selection and hyperparameter tuning
- Evaluation with ROC-AUC and F1 metrics
- Submission to Kaggle for leaderboard evaluation




# PNN Models Assignment-- --> **HW_5.ipynb**

This notebook explores Probabilistic Neural Networks (PNN) and compares their performance with other supervised learning models.

## Highlights
- Implemented PNN using NumPy and scikit-learn.
- Compared accuracy and computational efficiency against traditional feedforward networks.
- Evaluated model performance on a benchmark dataset.



# Math482 â€“ Assignment 4: Derivation of Loss Functions

In this assignment, the objective is to **derive loss functions** starting from the probability distribution of a dataset and understand how different artificial intelligence models are trained under various distributional assumptions.

## ğŸ“˜ Purpose
The main goal is to learn how to mathematically derive a loss function using the **Gaussian (normal) distribution**, and to connect this derivation to commonly used functions in machine learning such as **MSE (Mean Squared Error)**.

Specifically, this notebook includes:
- Derivation of the loss function directly from the **negative log-likelihood** of the Gaussian distribution.  
- Implementation and comparison of its simplified form, the **MSE loss function**.  
- Integration of the derived loss into an existing neural network structure (activation, forward/backward propagation, training functions).

## ğŸ§  Learning Outcomes
By completing this notebook, you will:
- Understand the relationship between probability theory and optimization in neural networks.  
- See how assumptions on data distribution influence the form of the loss function.  
- Implement and analyze loss derivations in a Jupyter Notebook environment.

## âš™ï¸ Environment
- **Language:** Python  
- **Libraries:** NumPy, Matplotlib  
- **Platform:** Jupyter Notebook

---

**Author:** Ozan GÃ¼rcÃ¼oÄŸlu  
**Course:** Math482 â€“ Machine Learning Theory  
**Date:** November 2025




# ğŸ©º Diabetes Prediction Project

Bu proje, hastalarÄ±n tÄ±bbi Ã¶lÃ§Ã¼mlerini kullanarak diyabet riskini tahmin etmek amacÄ±yla geliÅŸtirilmiÅŸ bir **Makine Ã–ÄŸrenmesi** Ã§alÄ±ÅŸmasÄ±dÄ±r. Veri setindeki Ã§eÅŸitli saÄŸlÄ±k parametreleri analiz edilerek, bir kiÅŸinin diyabet hastasÄ± olup olmadÄ±ÄŸÄ± yÃ¼ksek doÄŸruluk oranÄ±yla Ã¶ngÃ¶rÃ¼lmeye Ã§alÄ±ÅŸÄ±lmÄ±ÅŸtÄ±r.

## ğŸš€ Proje Ã–zeti
Diyabet, dÃ¼nya genelinde milyonlarca insanÄ± etkileyen kronik bir hastalÄ±ktÄ±r. Erken teÅŸhis, hastalÄ±ÄŸÄ±n yÃ¶netimi iÃ§in kritiktir. Bu proje; veri temizleme, Ã¶zellik mÃ¼hendisliÄŸi (feature engineering) ve sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ± kullanarak saÄŸlÄ±k verilerinden anlamlÄ± sonuÃ§lar Ã§Ä±karmayÄ± hedefler.



## ğŸ› ï¸ KullanÄ±lan Teknolojiler & KÃ¼tÃ¼phaneler
* **Dil:** Python 3.x
* **Veri Analizi:** Pandas, NumPy
* **GÃ¶rselleÅŸtirme:** Matplotlib, Seaborn
* **Makine Ã–ÄŸrenmesi:** Scikit-learn (Logistic Regression, Random Forest, SVM vb.)
* **Model Kaydetme:** Pickle / Joblib

## ğŸ“Š Veri Seti HakkÄ±nda
Projede (Ã¶rneÄŸin: Pima Indians Diabetes Dataset) kullanÄ±lmÄ±ÅŸtÄ±r. Temel Ã¶zellikler ÅŸunlardÄ±r:
* **Pregnancies:** Gebelik sayÄ±sÄ±
* **Glucose:** Glikoz deÄŸeri
* **Blood Pressure:** Kan basÄ±ncÄ±
* **BMI:** VÃ¼cut kitle indeksi
* **Age:** YaÅŸ
* **Outcome:** Diyabet durumu (0: Negatif, 1: Pozitif)

## ğŸ—ï¸ Ä°ÅŸ AkÄ±ÅŸÄ± (Workflow)
1. **Veri Ã–n Ä°ÅŸleme:** Eksik deÄŸerlerin (0 olan mantÄ±ksÄ±z veriler) analizi ve doldurulmasÄ±.
2. **EDA (KeÅŸifÃ§i Veri Analizi):** Korelasyon matrisleri ve daÄŸÄ±lÄ±m grafiklerinin incelenmesi.
3. **Ã–zellik Ã–lÃ§eklendirme:** StandardScaler veya MinMaxScaler kullanÄ±mÄ±.
4. **Model EÄŸitimi:** FarklÄ± algoritmalarÄ±n (Random Forest, XGBoost vb.) karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±.
5. **DeÄŸerlendirme:** Confusion Matrix, F1-Score ve Accuracy deÄŸerlerinin analizi.

## ğŸ“ˆ SonuÃ§lar
Modelimiz test verileri Ã¼zerinde ÅŸu baÅŸarÄ± metriklerini elde etmiÅŸtir:
* **Accuracy:** %XX
* **Precision:** %XX
* **Recall:** %XX

## ğŸ’» Kurulum ve Ã‡alÄ±ÅŸtÄ±rma
Projeyi yerel bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

1. Depoyu klonlayÄ±n:
   ```bash
   git clone [https://github.com/kullaniciadi/diabetes-prediction.git](https://github.com/kullaniciadi/diabetes-prediction.git)
